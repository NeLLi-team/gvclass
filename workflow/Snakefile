from pathlib import Path
import glob


""" Assign taxonomy to NCDLV contigs or MAGs """

"""
Input is single file with contig or collection of contigs
File ending ".fna" (nucleic acid) or ".faa" (amino acid)
No special characters in filename, no additional "."
Recommended assembly size is 50kb

Example run:
snakemake -j 8 --use-conda --config querydir="example"
"""


# input and output dirs
querydir = Path(config["querydir"])
gvog9dir="resources/gvog9/"
outdir = config["querydir"] + "/results/"
# query file bases = query names without suffix
QUERYBASENAMES = [x.stem for x in querydir.iterdir() if x.is_file() and x.suffix in [".faa", ".fna"]]
FNAQUERY = [x.stem for x in querydir.iterdir() if x.is_file() and x.suffix in [".fna"]]
FAAQUERY = [x.stem for x in querydir.iterdir() if x.is_file() and x.suffix in [".faa"]]
# model names
GVOG9 = [x.split("/")[-1].split(".")[0] for x in glob.glob(gvog9dir + "*.hmm")]
# labels file for tax assignments
labels = "resources/ncldvOct22_labels.txt"


rule all:
  input:
    expand(outdir + "{querybase}.tar.gz", querybase=QUERYBASENAMES),
    outdir + "gvclass_out.tab"


""" 
Step 0 
Genecalling to find optimal translation table 
"""


rule reformat_faa:
  """
  check format of faa input and reformat
  reformat headers to ><filenamebase>|<proteinid> 
  create summary stats, asssembly size, GC, coding density, gene count
  if faa provided add gene count only
  """
  conda:
    "envs/gvclass.yml"
  input:
    str(querydir) + "/{querybase}.faa"
  log:
    outdir + "{querybase}/log/reformat/{querybase}.log"
  output:
    outdir + "{querybase}/query_faa/{querybase}.faa",
    outdir + "{querybase}/stats/{querybase}.stats.tab"
  shell:
    """
    (python workflow/scripts/00reformat.py -i {input} -o {output[0]} -s {output[1]}) &> {log}
    """


rule genecalling:
  """
  Genecalling with different translation tables
  Find code that optimizes coding density
  """
  conda:
    "envs/gvclass.yml"
  input:
    str(querydir) + "/{querybase}.fna"
  log:
    outdir + "{querybase}/log/genecalling/{querybase}.log"
  output:
    gffout = outdir + "{querybase}/genecalling/{querybase}.gff",
    genecalling_statsout = outdir + "{querybase}/stats/{querybase}.genecalling.tab",
    best_statsout = outdir + "{querybase}/stats/{querybase}.stats.tab",
    faafinalout = outdir + "{querybase}/query_faa/{querybase}.faa",
    fnafinalout = outdir + "{querybase}/query_fna/{querybase}.fna"
  shell:
    """
    python workflow/scripts/01genecalling_single.py -f {input} -g {output.gffout} -gs {output.genecalling_statsout} -ss {output.best_statsout} -fa {output.faafinalout} &> {log}
    cp {input} {output.fnafinalout}
    """


rule predict_fna:
  """
  Predict if fna is NCDLV and if yes predict order level lineage
  """
  conda:
    "envs/xgb.yml"
  input:
    xgbD = "resources/classifier/domain_xgb.sav",
    featuresD = "resources/classifier/domain_features.txt",
    mappingsD = "resources/classifier/domain_mapping.tab"
  params:
    infilebase = str(querydir) + "/{querybase}"
  log:
    outdir + "{querybase}/log/xgb/{fnaquerybase}.log"
  output:
    outdir + "{querybase}/xgb/{fnaquerybase}.xgb.tab"
  shell:
    """
    if [ -f {params.infilebase}.fna ]; then
    python workflow/scripts/01predict.py -q {params.infilebase}.fna -m {input.xgbD} -k {input.featuresD} -l {input.mappingsD} -o {output} &> {log};
    else touch {output}; fi
    """


"""
Step 1 
Identify markers, extract, align
"""

rule run_hmmsearch_GVOG9:
  """
  hmmsearch to identify 9 conserved GVOGs in query sequences
  """
  conda:
    "envs/gvclass.yml"
  input:
    queryfaa = outdir + "{querybase}/query_faa/{querybase}.faa",
    models = "resources/GVOG9.hmm"
  log:
    outdir + "{querybase}/log/hmmsearch/{querybase}.log"
  output:
    GVOG9out = outdir + "{querybase}/hmmout/GVOG9.out",
    hitcounts = outdir + "{querybase}/hmmout/GVOG9.counts"
  shell:
    """
    (python workflow/scripts/02hmmsearch.py -q {input.queryfaa} -m {input.models} -h {output.GVOG9out} -t GVOG9 -c {output.hitcounts}) &> {log}
    """


rule run_hmmsearch_UNI:
  """
  hmmsearch to identify UNI56 in query sequences
  mainly to estimate cellular contamination
  """
  conda:
    "envs/gvclass.yml"
  input:
    queryfaa = outdir + "{querybase}/query_faa/{querybase}.faa",
    models = "resources/UNI56.hmm"
  log:
    outdir + "{querybase}/log/hmmsearch/{querybase}_UNI56.log"
  output:
    UNI56out = outdir + "{querybase}/hmmout/UNI56.out",
    hitcounts = outdir + "{querybase}/hmmout/UNI56.counts"
  shell:
    """
    (python workflow/scripts/02hmmsearch.py -q {input.queryfaa} -m {input.models} -h {output.UNI56out} -t UNI56 -c {output.hitcounts}) &> {log}
    """


rule extract_qhits:
  """
  extract hits from hmmsearch, one file per marker, merge with refs
  """
  conda:
    "envs/gvclass.yml"
  input:
    hmmout = outdir + "{querybase}/hmmout/GVOG9.out",
    queryfaa = outdir + "{querybase}/query_faa/{querybase}.faa"
  output:
    queryhitsfaa = outdir + "{querybase}/query_hits_faa/{modelbase}.faa"
  shell:
    """
    python workflow/scripts/03extract_qhits.py -h {input.hmmout} -q {input.queryfaa} -o {output.queryhitsfaa}
    touch {output.queryhitsfaa}
    """


rule blastp_reduce_merge:
  """
  blastp vs databases of representative genomes
  extract up to top 100 hits
  """
  conda:
    "envs/gvclass.yml"
  log:
    outdir + "{querybase}/log/diamond/{querybase}_{modelbase}.log"
  input:
    queryhitsfaa = outdir + "{querybase}/query_hits_faa/{modelbase}.faa",
    reffaa = "resources/refsGVOG9/faa/{modelbase}.faa",
    refdb = "resources/refsGVOG9/dmnd/{modelbase}.dmnd"
  output:
    blastpout = outdir + "{querybase}/blastp_out/{modelbase}.m8",
    mergedfaa = outdir + "{querybase}/query_hits_merged_faa/{modelbase}.faa"
  shell:
    """
    (python workflow/scripts/04blastp_reduce_merge.py -q {input.queryhitsfaa} -r {input.reffaa} -d {input.refdb} -b {output.blastpout} -o {output.mergedfaa}) >& {log}
    touch {output.blastpout} {output.mergedfaa}
    """


rule align_trim:
  """
  align extracted GVOGs together with refs
  """
  conda:
    "envs/gvclass.yml"
  log:
    outdir + "{querybase}/log/hmmsearch/{querybase}_{modelbase}.log"
  input:
    mergedfaa = outdir + "{querybase}/query_hits_merged_faa/{modelbase}.faa"
  output:
    aln = outdir + "{querybase}/queryrefs_aligned/{modelbase}.mafft",
    trimmedaln = outdir + "{querybase}/queryrefs_aligned/{modelbase}.mafft01"
  shell:
    """
    (python workflow/scripts/05align_trim.py -q {input.mergedfaa} -a {output.aln} -t {output.trimmedaln}) >& {log}
    touch {output.aln} {output.trimmedaln}
    """


"""
Step 2 - Tree based
Build protein trees, get nearest neighbor in trees
"""

rule build_trees:
  """
  build single protein trees for GVOG
  """
  conda:
    "envs/gvclass.yml"
  log:
    outdir + "{querybase}/log/trees/{querybase}_{modelbase}.log"
  input:
    trimmedaln = outdir + "{querybase}/queryrefs_aligned/{modelbase}.mafft01"
  output:
    tree = outdir + "{querybase}/queryrefs_fasttree/{modelbase}.FTWAG"
  shell:
    """
    (python workflow/scripts/06build_tree.py -a {input.trimmedaln} -t {output.tree}) >& {log}
    touch {output.tree}
    """


rule get_nn:
  """
  infer nearest neighbor in each tree
  """
  conda:
    "envs/gvclass.yml"
  params:
    queryname="{querybase}",
    fdir = outdir + "{querybase}"
  input:
    ft = expand(outdir + "{querybase}/queryrefs_fasttree/{modelbase}.FTWAG", querybase="{querybase}", modelbase=GVOG9),
    alnt = expand(outdir + "{querybase}/queryrefs_aligned/{modelbase}.mafft01", querybase="{querybase}", modelbase=GVOG9)
  log:
    outdir + "{querybase}/log/nn/{querybase}.log"
  output:
    tree_out = outdir + "{querybase}/stats/{querybase}.tree_nn",
    aln_out = outdir + "{querybase}/stats/{querybase}.aln_nn"
  shell: 
    """
    (python workflow/scripts/07get_nn_aln.py -q {params.queryname} -a {params.fdir}/queryrefs_aligned/ -o {output.aln_out} -l {labels}
    python workflow/scripts/08get_nn_tree.py -q {params.queryname} -t {params.fdir}/queryrefs_fasttree/ -o {output.tree_out} -l {labels}) &> {log}
    """


rule summarize:
  """
  combine different outputs
  """
  conda:
    "envs/gvclass.yml"
  input:
    nn_tree = outdir + "{querybase}/stats/{querybase}.tree_nn",
    gvog9_count = outdir + "{querybase}/hmmout/GVOG9.counts",
    uni56_count = outdir + "{querybase}/hmmout/UNI56.counts",
    querystats = outdir + "{querybase}/stats/{querybase}.stats.tab",
    xgbout = outdir + "{querybase}/xgb/{querybase}.xgb.tab"
  log:
    outdir + "{querybase}/log/summarize/{querybase}.log"
  output:
    outdir + "{querybase}/{querybase}.summary.tab"
  shell:
    """
    (python workflow/scripts/09summarize.py -n {input.nn_tree} -g {input.gvog9_count} -u {input.uni56_count} -q {input.querystats} -s {output} -c {input.xgbout}
    touch {output}) &> {log}
    """


rule combinedout:
  """
  combined output of highest stringency for predicted giant viruses
  """
  conda:
    "envs/gvclass.yml"
  input:
    expand(outdir + "{querybase}/{querybase}.summary.tab", querybase=QUERYBASENAMES)
  params:
    fdirp = outdir
  output:
    combined = outdir + "gvclass_out.tab"
  shell:
    """
    python workflow/scripts/10combinedout.py -r {params.fdirp} -o {output.combined}
    touch {output.combined}
    """


rule cleanup:
  """
  intermediate files are kept including empty files, compress output 
  """
  conda:
    "envs/gvclass.yml"
  input:
    combined = outdir + "gvclass_out.tab"
  params:
    fdir = outdir + "{querybase}"
  output:
    outdir + "{querybase}.tar.gz"
  shell:
    """
    #find {params.fdir} -type f -empty -print -delete
    python workflow/scripts/11cleanup.py -r {params.fdir} -o {output}
    """

